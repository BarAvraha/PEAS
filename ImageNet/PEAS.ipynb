{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ufVpC5N_mhOi",
   "metadata": {
    "id": "ufVpC5N_mhOi"
   },
   "source": [
    "#PEAS\n",
    "\n",
    "This notebook demonstrates how to enhance baseline transfer attacks using the PEAS.\n",
    "\n",
    "**Overview:**\n",
    "\n",
    "In this notebook, you will find:\n",
    "* PEAS Class Implementation: Define and utilize the PEAS class to generate adversarial examples under different augmentation scenarios.\n",
    "\n",
    "* Parameter Definitions: Set up victim and substitute models, augmentation techniques, and attack parameters.\n",
    "\n",
    "* Dataset Preparation: Load and preprocess the CIFAR-10 dataset, selecting correctly classified samples for evaluation.\n",
    "\n",
    "* Baseline Transfer Attack: Define the baseline transfer attack (e.g., PGD) to be boosted by PEAS.\n",
    "\n",
    "* Attack Success Rate (ASR) Calculation: Evaluate the effectiveness of the generated adversarial examples against a victim model.\n",
    "\n",
    "\n",
    "The results will vary slightly between runs due to the random processes (augmentations and selection of images). This notebook has been setup to work on CIFAR-10 and can be adapted to other datasets. It is designed to boost any non-query based attack (e.g., BTA, PGN, TIMI).\n",
    "\n",
    "**Getting Started:**\n",
    "\n",
    "To begin, ensure you have all necessary libraries installed and run the cells in order. You can modify model names, parameters, and transformations as needed to fit your specific requirements. Each section includes detailed comments and explanations to guide you through the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F18YPiFZ6bR5",
   "metadata": {
    "id": "F18YPiFZ6bR5"
   },
   "source": [
    "##Install and Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6413908-2b7e-4e26-90dd-1863993135c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6413908-2b7e-4e26-90dd-1863993135c4",
    "outputId": "710298d6-ea34-406e-9447-488f44da66cb"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchattacks import PGD\n",
    "import numpy as np\n",
    "from torchvision.transforms import v2\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "from pprint import pprint\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75fdbfbd-4821-4d31-820c-aa5ecda819bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75fdbfbd-4821-4d31-820c-aa5ecda819bf",
    "outputId": "49c9fdd5-03a8-421a-d989-8b791aa6d064"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GrZ3V7hC8M57",
   "metadata": {
    "id": "GrZ3V7hC8M57"
   },
   "source": [
    "##PEAS Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa192f4-cdad-4001-9dfa-3df5a05dbfe8",
   "metadata": {
    "id": "7fa192f4-cdad-4001-9dfa-3df5a05dbfe8"
   },
   "outputs": [],
   "source": [
    "class PEAS:\n",
    "    def __init__(self, F, g, S, trans, attack, count=200):\n",
    "        \"\"\"\n",
    "        Initializes the PEAS class.\n",
    "\n",
    "        Parameters:\n",
    "        - F (list): A list of models that will be used to evaluate the generated adversarial examples.\n",
    "        - g (model): The surrogate model used for generating adversarial examples.\n",
    "        - S (int): The scenario for augmentation: 0 (no augmentation), 1 (single augmentation), 2 (mix of augmentations).\n",
    "        - trans (list): The list of augmentations to apply.\n",
    "        - count (int, optional): The number of attack iterations to perform. Defaults to 200.\n",
    "        \"\"\"\n",
    "\n",
    "        self.F = F\n",
    "        self.g = g\n",
    "        self.S = S\n",
    "        self.trans = trans\n",
    "        self.count = count\n",
    "        self.attack = attack\n",
    "\n",
    "    def generate(self, x, y):\n",
    "\n",
    "        \"\"\"\n",
    "        Generates adversarial examples using the selected attack under various settings.\n",
    "\n",
    "        Parameters:\n",
    "        - x (Tensor): The input images.\n",
    "        - y (Tensor): The correct labels for the input images.\n",
    "\n",
    "        Returns:\n",
    "        - adv_x (Tensor): The generated adversarial examples.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = len(x)\n",
    "        best_attacks = []\n",
    "        min_confidences = [float('inf')] * batch_size\n",
    "\n",
    "        for _ in tqdm(range(self.count)):\n",
    "\n",
    "\n",
    "            if self.S==0: #without augmentations\n",
    "                x_a = self.attack(x, y)\n",
    "\n",
    "            if self.S==1: #PEAS S1 - one augmentation\n",
    "                x_a = random.choice(self.trans)(x)\n",
    "            \n",
    "                images_min = clip_by_tensor(x - epsilon, 0.0, 1.0)\n",
    "                images_max = clip_by_tensor(x + epsilon, 0.0, 1.0)\n",
    "                x_p = PGN(x_a, y, g, images_min, images_max)\n",
    "\n",
    "            elif self.S==2: #PEAS S2 - mixing augmentations\n",
    "                augmentations = transforms.Compose(self.trans)\n",
    "                x_a = augmentations(x)\n",
    "                x_a = self.attack(x_a, y)\n",
    "\n",
    "            average_confidences =  np.zeros(batch_size, dtype=np.float32)\n",
    "\n",
    "\n",
    "            for model in self.F:\n",
    "                outputs = model(x_a).softmax(dim=1)\n",
    "                confidences = outputs[torch.arange(outputs.size(0)),y].detach().cpu().numpy()\n",
    "                average_confidences += confidences\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "            average_confidences /= len(F)\n",
    "\n",
    "            # Compare and select the attack with the lowest average confidence for each image\n",
    "            for i in range(batch_size):\n",
    "                if average_confidences[i] < min_confidences[i]:\n",
    "                    if len(best_attacks) < batch_size:\n",
    "                        best_attacks.append(x_a[i])\n",
    "                    else:\n",
    "                        best_attacks[i] = x_a[i]\n",
    "                    min_confidences[i] = average_confidences[i]\n",
    "\n",
    "        # Stack the selected attacks\n",
    "        adv_x = torch.stack(best_attacks)\n",
    "        return adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "QHvPt4l8D2Fn",
   "metadata": {
    "id": "QHvPt4l8D2Fn"
   },
   "outputs": [],
   "source": [
    "class model_with_normalization(nn.Module):\n",
    "    def __init__(self, model, normalization):\n",
    "        super(model_with_normalization, self).__init__()\n",
    "        self.model = model \n",
    "        self.normalization = normalization\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.normalization(x)\n",
    "        if x.shape == (3,224,224):\n",
    "          x = x.unsqueeze(0)\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "normalization = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RT4cZW518QV9",
   "metadata": {
    "id": "RT4cZW518QV9"
   },
   "source": [
    "##Parameters\n",
    "Define the names of the victim and substitute models, and the set of augmentation algorithms for subtle transformations. You can change these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775151da-2d7d-4dcf-9122-e9ca137b26b0",
   "metadata": {
    "id": "775151da-2d7d-4dcf-9122-e9ca137b26b0"
   },
   "outputs": [],
   "source": [
    "#The basline tranfer attack to boost by PEAS\n",
    "epsilon = 2/255\n",
    "#Set of augmentation algorithms, each configured to perform a subtle augmentation. S1: random augmentation from the set , S2: applies all augmentations from the set.\n",
    "trans = [\n",
    "    transforms.RandomAffine(degrees=(-4,4), translate=(0.1, 0.1)), # Reduced degree of rotation and translation\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05), # Subtle color adjustments\n",
    "    transforms.RandomCrop(size=(32,32), padding=3), # Adjust padding if needed\n",
    "    transforms.GaussianBlur(kernel_size=1.9), # Smaller kernel for subtle blur\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=1.5), # Gentle sharpness adjustment\n",
    "    transforms.RandomAutocontrast()] # Generally subtle, adjust if necessary\n",
    "\n",
    "#Number of augmentations per input\n",
    "count = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1562979a-5125-42e0-85aa-29b66fb21210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________\n",
      "Victim: vit_b_16\n",
      "g: efficientnet_b0\n",
      "g: swin_s\n",
      "g: densenet121\n",
      "g: resnet18\n"
     ]
    }
   ],
   "source": [
    "for i , (name_v, model_v, weights_v) in enumerate(models): \n",
    "    if i==0:\n",
    "        victim = model_v(weights=weights_v.DEFAULT)\n",
    "        print(\"______________________\")\n",
    "        print(\"Victim: \"+ name_v)\n",
    "    \n",
    "        S = models.copy()\n",
    "        S.pop(i)\n",
    "        victim = model_with_normalization(victim, normalization)\n",
    "        victim.eval()\n",
    "        victim = victim.to(device)\n",
    "        \n",
    "        with open('../data_'+name_v+'1000images.pkl', 'rb') as f:\n",
    "            new_data_loader = pickle.load(f)\n",
    "\n",
    "        for j , (name_g,model_g, weights_g) in enumerate(S):\n",
    "           print(\"g: \"+ name_g) \n",
    "           g = model_g(weights=weights_g.DEFAULT) \n",
    "           Se = S.copy()\n",
    "           Se.pop(j)\n",
    "           g = model_with_normalization(g, normalization)\n",
    "\n",
    "           g.eval()\n",
    "           g = g.to(device)\n",
    "           PGD_attack = PGD(g, eps=epsilon , alpha=random.uniform(0.1/255, 0.3/255), steps=random.randint(10, 20), random_start=True)\n",
    "           \n",
    "           \n",
    "            \n",
    "           F = []\n",
    "           for n , model_s, weights_s in Se:\n",
    "                model = model_s(weights=weights_s.DEFAULT)\n",
    "                model = model.to(device)\n",
    "                model = model_with_normalization(model, normalization)\n",
    "                model.to(device)\n",
    "                model.eval()\n",
    "                F.append(model)\n",
    "               \n",
    "           ASR = {'Original': 0 , 'PEAS_S1': 0, 'PEAS_S2': 0}    \n",
    "           for batch, (x, y) in enumerate(new_data_loader):\n",
    "               \n",
    "               images_min = clip_by_tensor(images - epsilon, 0.0, 1.0)\n",
    "               images_max = clip_by_tensor(images + epsilon, 0.0, 1.0)\n",
    "               x_p = PGN(images, labels, g, images_min, images_max)\n",
    "               adv_label_p = victim(x_p).argmax(dim=1)\n",
    "               adv_label = adv_label.to('cpu')\n",
    "               ASR['Original'] += int((y != adv_label).int().sum())\n",
    "\n",
    "               #S1: ONE augmentations\n",
    "               PEAS_attack = PEAS(F,g, 1, trans, PGD_attack, count=count)\n",
    "               x_a = PEAS_attack.generate(x, y)\n",
    "               x_a = x_a.to(device)\n",
    "               adv_label = victim(x_a).argmax(dim=1)\n",
    "               adv_label = adv_label.to('cpu')\n",
    "               ASR['PEAS_S1'] += int((y != adv_label).int().sum())\n",
    "            \n",
    "            \n",
    "               #S2: mixing augmentations\n",
    "                PEAS_attack = PEAS(F,g, 2, trans, PGD_attack, count=count)\n",
    "                x_a = PEAS_attack.generate(x, y)\n",
    "                x_a = x_a.to(device)\n",
    "                adv_label = victim(x_a).argmax(dim=1)\n",
    "                adv_label = adv_label.to('cpu')\n",
    "                ASR['PEAS_S2'] += int((y != adv_label).int().sum())\n",
    "\n",
    "\n",
    "print(ASR) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "te0URMF4Cg-6",
   "metadata": {
    "id": "te0URMF4Cg-6"
   },
   "source": [
    "##Load and Normalize the Selected Models\n",
    " Load the sselected models from PyTorch Hub, apply normalization, and set the models to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "UAcuEkYeB-D_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UAcuEkYeB-D_",
    "outputId": "fb541317-21bd-4ad4-e067-94f477dae880"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar10_resnet20-4118986f.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_resnet20-4118986f.pt\n",
      "100%|██████████| 1.09M/1.09M [00:00<00:00, 48.2MB/s]\n",
      "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/vgg/cifar10_vgg11_bn-eaeebf42.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_vgg11_bn-eaeebf42.pt\n",
      "100%|██████████| 37.3M/37.3M [00:00<00:00, 49.3MB/s]\n",
      "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/mobilenetv2/cifar10_mobilenetv2_x0_5-ca14ced9.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_mobilenetv2_x0_5-ca14ced9.pt\n",
      "100%|██████████| 2.85M/2.85M [00:02<00:00, 1.22MB/s]\n",
      "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/shufflenetv2/cifar10_shufflenetv2_x1_5-296694dd.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_shufflenetv2_x1_5-296694dd.pt\n",
      "100%|██████████| 9.69M/9.69M [00:00<00:00, 55.9MB/s]\n",
      "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/repvgg/cifar10_repvgg_a0-ef08a50e.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_repvgg_a0-ef08a50e.pt\n",
      "100%|██████████| 30.1M/30.1M [00:00<00:00, 43.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Victim Model\n",
    "victim = models[victim_name][0](weights=models[victim_name][1].DEFAULT)\n",
    "victim = model_with_normalization(victim, normalization)\n",
    "victim = victim.to(device)\n",
    "victim.eval()\n",
    "\n",
    "\n",
    "#Substitute model to generate adversarial examples\n",
    "g = models[substitute_name][0](weights=models[substitute_name][1].DEFAULT)\n",
    "g = model_with_normalization(g, normalization)\n",
    "g.eval()\n",
    "g = g.to(device)\n",
    "\n",
    "\n",
    "#Set of substitute models to compute ET score\n",
    "F = []\n",
    "for model_name in substitute_models_name:\n",
    "    model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_\"+model_name, pretrained=True, verbose=False)\n",
    "    model = model.to(device)\n",
    "    model = model_with_normalization(model, normalization)\n",
    "    model.eval()\n",
    "    F.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ua0M-EW2mAMa",
   "metadata": {
    "id": "ua0M-EW2mAMa"
   },
   "source": [
    "##Basline Tranfer Attack\n",
    "Select the baseline attack to be boosted by PEAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eKpvrnDFsn72",
   "metadata": {
    "id": "eKpvrnDFsn72"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "-f8Ka-_Q-VQ3",
   "metadata": {
    "id": "-f8Ka-_Q-VQ3"
   },
   "source": [
    "##Calculate Attack Success Rate (ASR)\n",
    "Calculate the ASR for three scenarios: Vanilla (no augmentations), PEAS_S1 (single augmentation), and PEAS_S2 (mix of augmentations). Generate adversarial examples using the PEAS framework and evaluate them against the victim model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfa0bb1b-7b79-4115-8f29-69e9efab6701",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfa0bb1b-7b79-4115-8f29-69e9efab6701",
    "outputId": "2970361e-1e40-4a29-d356-b74a6f5e926f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:01<00:00,  3.28it/s]\n",
      "100%|██████████| 200/200 [01:08<00:00,  2.91it/s]\n",
      "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
      "100%|██████████| 200/200 [01:06<00:00,  2.99it/s]\n",
      "100%|██████████| 200/200 [01:30<00:00,  2.22it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.23it/s]\n",
      "100%|██████████| 200/200 [01:06<00:00,  3.00it/s]\n",
      "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.23it/s]\n",
      "100%|██████████| 200/200 [01:05<00:00,  3.04it/s]\n",
      "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
      "100%|██████████| 200/200 [01:02<00:00,  3.23it/s]\n",
      "100%|██████████| 200/200 [01:06<00:00,  3.01it/s]\n",
      "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
      "100%|██████████| 200/200 [01:06<00:00,  3.01it/s]\n",
      "100%|██████████| 200/200 [01:30<00:00,  2.22it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
      "100%|██████████| 200/200 [01:05<00:00,  3.04it/s]\n",
      "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
      "100%|██████████| 200/200 [01:07<00:00,  2.97it/s]\n",
      "100%|██████████| 200/200 [01:30<00:00,  2.22it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.25it/s]\n",
      "100%|██████████| 200/200 [01:06<00:00,  3.02it/s]\n",
      "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
      "100%|██████████| 200/200 [01:02<00:00,  3.22it/s]\n",
      "100%|██████████| 200/200 [01:06<00:00,  2.99it/s]\n",
      "100%|██████████| 200/200 [01:29<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Vanilla': 200, 'PEAS_S1': 363, 'PEAS_S2': 528}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ASR = {'Vanilla': 0 , 'PEAS_S1': 0, 'PEAS_S2': 0}\n",
    "\n",
    "\n",
    "with open('../data_'+name_v+'1000images.pkl', 'rb') as f:\n",
    "        new_data_loader = pickle.load(f)\n",
    "    \n",
    "for batch, (x, y) in enumerate(new_data_loader):\n",
    "\n",
    "    #vanilla-no augmetations\n",
    "    PEAS_attack = PEAS(F,g, 0, trans, PGD_attack, count=count)\n",
    "    x_a = PEAS_attack.generate(x, y)\n",
    "    x_a = x_a.to(device)\n",
    "    adv_label = victim(x_a).argmax(dim=1)\n",
    "    adv_label = adv_label.to('cpu')\n",
    "    ASR['Vanilla'] += int((y != adv_label).int().sum())\n",
    "\n",
    "    #S1: ONE augmentations\n",
    "    PEAS_attack = PEAS(F,g, 1, trans, PGD_attack, count=count)\n",
    "    x_a = PEAS_attack.generate(x, y)\n",
    "    x_a = x_a.to(device)\n",
    "    adv_label = victim(x_a).argmax(dim=1)\n",
    "    adv_label = adv_label.to('cpu')\n",
    "    ASR['PEAS_S1'] += int((y != adv_label).int().sum())\n",
    "\n",
    "\n",
    "    #S2: mixing augmentations\n",
    "    PEAS_attack = PEAS(F,g, 2, trans, PGD_attack, count=count)\n",
    "    x_a = PEAS_attack.generate(x, y)\n",
    "    x_a = x_a.to(device)\n",
    "    adv_label = victim(x_a).argmax(dim=1)\n",
    "    adv_label = adv_label.to('cpu')\n",
    "    ASR['PEAS_S2'] += int((y != adv_label).int().sum())\n",
    "\n",
    "\n",
    "print(ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "915d25c7-ff40-4089-bc6d-8a54cadc787f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "915d25c7-ff40-4089-bc6d-8a54cadc787f",
    "outputId": "96b6b878-4bc4-494f-e1ab-1792b151f8da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Success Rates (ASR) on CIFAR10, victim: resnet20, Substitute: vgg11_bn\n",
      "Vanilla: 0.2\n",
      "PEAS_S1: 0.363\n",
      "PEAS_S2: 0.528\n"
     ]
    }
   ],
   "source": [
    "print(f\"Adversarial Success Rates (ASR) on CIFAR10, victim: {victim_name}, Substitute: {substitute_name}\")\n",
    "for method, rate in ASR.items():\n",
    "    print(f\"{method}: {rate/1000}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "F18YPiFZ6bR5"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "TEST_GPU",
   "language": "python",
   "name": "test_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
