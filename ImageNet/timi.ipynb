{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d5aa27-12e1-43e7-9eca-84a811b826ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baravrah/.conda/envs/gpu_test/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/baravrah/.conda/envs/gpu_test/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/baravrah/.conda/envs/gpu_test/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "# from art.attacks.evasion import ProjectedGradientDescentPyTorch\n",
    "from torchattacks import PGD, TIFGSM\n",
    "from art.utils import random_sphere\n",
    "from art.config import ART_NUMPY_DTYPE\n",
    "import numpy as np\n",
    "from torchvision.transforms import v2\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights, vgg19 , VGG19_Weights, resnet18, ResNet18_Weights, densenet121,  densenet121, DenseNet121_Weights, vit_b_16, ViT_B_16_Weights, efficientnet_b2, EfficientNet_B2_Weights,  swin_s, Swin_S_Weights, convnext_base, ConvNeXt_Base_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c49aec-a35a-48a8-a12f-6c808129853e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4049f8-efa8-428e-9ad1-edd186f741e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [(\"vit_b_16\",vit_b_16, ViT_B_16_Weights),\n",
    "          (\"efficientnet_b0\" , efficientnet_b0, EfficientNet_B0_Weights),\n",
    "          (\"swin_s\", swin_s, Swin_S_Weights),\n",
    "          (\"densenet121\" , densenet121, DenseNet121_Weights),\n",
    "          (\"resnet18\" ,resnet18, ResNet18_Weights)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbacab9c-19b5-4c8b-919a-e812f394826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_with_normalization(nn.Module):\n",
    "    def __init__(self, model, normalization):\n",
    "        super(model_with_normalization, self).__init__()\n",
    "        self.model = model \n",
    "        self.normalization = normalization\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.normalization(x)\n",
    "        if x.shape == (3,224,224):\n",
    "          x = x.unsqueeze(0)\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "normalization = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f85c398-5f55-4665-9605-1c8188208474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Initialize your custom dataset\n",
    "# new_dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d072519-9255-409b-86bd-de643cf905d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_image(image_path):\n",
    "    return Image.open(image_path).convert('RGB')  # Ensure the image is in RGB format\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a74d890-5fc9-470b-918c-f330a0c8b14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________\n",
      "Victim: vit_b_16\n",
      "g: efficientnet_b0\n",
      "237\n",
      "g: swin_s\n",
      "291\n",
      "g: densenet121\n",
      "123\n",
      "g: resnet18\n",
      "102\n",
      "______________________\n",
      "Victim: efficientnet_b0\n",
      "g: vit_b_16\n",
      "196\n",
      "g: swin_s\n",
      "214\n",
      "g: densenet121\n",
      "181\n",
      "g: resnet18\n",
      "175\n",
      "______________________\n",
      "Victim: swin_s\n",
      "g: vit_b_16\n",
      "222\n",
      "g: efficientnet_b0\n",
      "175\n",
      "g: densenet121\n",
      "104\n",
      "g: resnet18\n",
      "85\n",
      "______________________\n",
      "Victim: densenet121\n",
      "g: vit_b_16\n",
      "219\n",
      "g: efficientnet_b0\n",
      "353\n",
      "g: swin_s\n",
      "213\n",
      "g: resnet18\n",
      "305\n",
      "______________________\n",
      "Victim: resnet18\n",
      "g: vit_b_16\n",
      "179\n",
      "g: efficientnet_b0\n",
      "343\n",
      "g: swin_s\n",
      "185\n",
      "g: densenet121\n",
      "317\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "batch_size = 100\n",
    "d = {}\n",
    "for i , (name_v, model_v, weights_v) in enumerate(models): \n",
    "        victim = model_v(weights=weights_v.DEFAULT)\n",
    "        print(\"______________________\")\n",
    "        print(\"Victim: \"+ name_v)\n",
    "    \n",
    "        S = models.copy()\n",
    "        S.pop(i)\n",
    "        victim = model_with_normalization(victim, normalization)\n",
    "        victim.eval()\n",
    "        victim = victim.to(device)\n",
    "        \n",
    "        with open('../data_'+name_v+'1000images.pkl', 'rb') as f:\n",
    "            new_data_loader = pickle.load(f)\n",
    "    \n",
    "        for j , (name_g,model_g, weights_g) in enumerate(S):\n",
    "                       row = [0,0,0]\n",
    "                       print(\"g: \"+ name_g) \n",
    "                       g = model_g(weights=weights_g.DEFAULT) \n",
    "                       Se = S.copy()\n",
    "                       Se.pop(j)\n",
    "                       g = model_with_normalization(g, normalization)\n",
    "                       g.eval()\n",
    "                       g = g.to(device)\n",
    "                       ASR = 0\n",
    "                       total_l2_score = 0\n",
    "            \n",
    "                       for batch , (images, labels) in enumerate(new_data_loader):\n",
    "                           #print(batch)\n",
    "                           labels =labels.to(device)\n",
    "                           #PGN\n",
    "                           TIFGSM_attack = TIFGSM(g, eps=12.75/255, alpha=0.2/255, steps=15)\n",
    "                           x_p = TIFGSM_attack(images, labels)\n",
    "                           adv_label_p = victim(x_p).argmax(dim=1)\n",
    "                           # adv_label_p = adv_label_p.to('cpu')\n",
    "                           ASR += (labels != adv_label_p).int().sum().item()\n",
    "                           #print(ASR)\n",
    "                           l2_score = torch.norm(images - x_p)\n",
    "                           total_l2_score += l2_score.sum().item()\n",
    "                           #print(l2_score)\n",
    "            \n",
    "                       d[f'{name_v}_{name_g}_ASR'] = ASR/1000\n",
    "                       d[f'{name_v}_{name_g}_L2'] = total_l2_score/1000\n",
    "                       print(ASR)\n",
    "with open('ranking_simba_baselines/TIMI.pkl', 'wb') as f:\n",
    "     pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9552c2f3-0d4f-4490-b0e4-d99b59bf5a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victim Model: vit_b_16\n",
      "  Average ASR: 0.1883\n",
      "  Average L2: 0.2244\n",
      "______________________\n",
      "Victim Model: efficientnet_b0\n",
      "  Average ASR: 0.1915\n",
      "  Average L2: 0.2151\n",
      "______________________\n",
      "Victim Model: swin_s\n",
      "  Average ASR: 0.1465\n",
      "  Average L2: 0.2329\n",
      "______________________\n",
      "Victim Model: densenet121\n",
      "  Average ASR: 0.2725\n",
      "  Average L2: 0.2289\n",
      "______________________\n",
      "Victim Model: resnet18\n",
      "  Average ASR: 0.2560\n",
      "  Average L2: 0.2242\n",
      "______________________\n"
     ]
    }
   ],
   "source": [
    "asr_totals = {}\n",
    "l2_totals = {}\n",
    "counts = {}\n",
    "\n",
    "# Loop over the models to collect the ASR and L2 scores\n",
    "for i, (name_v, model_v, weights_v) in enumerate(models): \n",
    "    victim = model_v(weights=weights_v.DEFAULT)\n",
    "    # print(\"______________________\")\n",
    "    # print(\"Victim: \" + name_v)\n",
    "    \n",
    "    S = models.copy()\n",
    "    S.pop(i)\n",
    "    \n",
    "    for j, (name_g, model_g, weights_g) in enumerate(S):\n",
    "        key_asr = f'{name_v}_{name_g}_ASR'\n",
    "        key_l2 = f'{name_v}_{name_g}_L2'\n",
    "        \n",
    "        if name_v not in asr_totals:\n",
    "            asr_totals[name_v] = 0\n",
    "            l2_totals[name_v] = 0\n",
    "            counts[name_v] = 0\n",
    "        \n",
    "        if key_asr in d:\n",
    "            asr_totals[name_v] += d[key_asr]\n",
    "        \n",
    "        if key_l2 in d:\n",
    "            l2_totals[name_v] += d[key_l2]\n",
    "        \n",
    "        counts[name_v] += 1\n",
    "\n",
    "# Calculate and print the average ASR and L2 scores for each victim model\n",
    "for victim in asr_totals:\n",
    "    avg_asr = asr_totals[victim] / counts[victim]\n",
    "    avg_l2 = l2_totals[victim] / counts[victim]\n",
    "    print(f\"Victim Model: {victim}\")\n",
    "    print(f\"  Average ASR: {avg_asr:.4f}\")\n",
    "    print(f\"  Average L2: {avg_l2:.4f}\")\n",
    "    print(\"______________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17fe8477-0681-4233-add6-e64a06cb45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from torch.cuda.amp import autocast\n",
    "trans = [\n",
    "    transforms.RandomAffine(degrees=(-2, 2), translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomCrop(size=(224, 224), padding=10),\n",
    "    transforms.GaussianBlur(kernel_size=3),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "    transforms.RandomAutocontrast()]\n",
    "\n",
    "\n",
    "augmentations = transforms.Compose(trans)\n",
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9acfa34f-4a91-4cca-9a4d-4d12e0512b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps = [\"vit_b_16\",\"efficientnet_b0\",\"swin_s\",\"densenet121\",\"resnet18\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4699f164-ff7f-410d-bced-de1292a42cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "e=12.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f9c957c-91cf-431f-8de9-8d6e72303e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________\n",
      "Victim: vit_b_16\n",
      "12.75\n",
      "g: efficientnet_b0\n",
      "0.236\n",
      "g: swin_s\n",
      "0.296\n",
      "g: densenet121\n",
      "0.126\n",
      "g: resnet18\n",
      "0.106\n",
      "______________________\n",
      "Victim: efficientnet_b0\n",
      "12.75\n",
      "g: vit_b_16\n",
      "0.198\n",
      "g: swin_s\n",
      "0.209\n",
      "g: densenet121\n",
      "0.183\n",
      "g: resnet18\n",
      "0.17\n",
      "______________________\n",
      "Victim: swin_s\n",
      "12.75\n",
      "g: vit_b_16\n",
      "0.221\n",
      "g: efficientnet_b0\n",
      "0.183\n",
      "g: densenet121\n",
      "0.101\n",
      "g: resnet18\n",
      "0.09\n",
      "______________________\n",
      "Victim: densenet121\n",
      "12.75\n",
      "g: vit_b_16\n",
      "0.213\n",
      "g: efficientnet_b0\n",
      "0.355\n",
      "g: swin_s\n",
      "0.219\n",
      "g: resnet18\n",
      "0.308\n",
      "______________________\n",
      "Victim: resnet18\n",
      "12.75\n",
      "g: vit_b_16\n",
      "0.171\n",
      "g: efficientnet_b0\n",
      "0.341\n",
      "g: swin_s\n",
      "0.185\n",
      "g: densenet121\n",
      "0.322\n"
     ]
    }
   ],
   "source": [
    "#using torchatacks\n",
    "results =[]\n",
    "for i , (name_v, model_v, weights_v) in enumerate(models): \n",
    "    victim = model_v(weights=weights_v.DEFAULT)\n",
    "    print(\"______________________\")\n",
    "    print(\"Victim: \"+ name_v)\n",
    "\n",
    "    S = models.copy()\n",
    "    S.pop(i)\n",
    "    victim = model_with_normalization(victim, normalization)\n",
    "    victim.eval()\n",
    "    victim = victim.to(device)\n",
    "    \n",
    "    with open('../data_'+name_v+'1000images.pkl', 'rb') as f:\n",
    "        new_data_loader = pickle.load(f)\n",
    "\n",
    "    results = []\n",
    "    print(e)\n",
    "    for j , (name_g,model_g, weights_g) in enumerate(S):\n",
    "\n",
    "               row = 0\n",
    "               print(\"g: \"+ name_g) \n",
    "               g = model_g(weights=weights_g.DEFAULT) \n",
    "               Se = S.copy()\n",
    "               Se.pop(j)\n",
    "               g = model_with_normalization(g, normalization)\n",
    "\n",
    "               g.eval()\n",
    "               g = g.to(device)\n",
    "               TIFGSM_attack = TIFGSM(g, eps=e/255, alpha=0.2/255, steps=15)\n",
    "               #PGD_attack = PGD(g, eps=e/255, alpha=random.uniform(0.1/255, 0.3/255), steps =random.randint(10, 20), random_start=True)\n",
    "\n",
    "               for batch , (images, labels) in enumerate(new_data_loader):\n",
    "                    # print(batch)\n",
    "                    if batch==10:\n",
    "                      break\n",
    "                  \n",
    "\n",
    "                    x_p = TIFGSM_attack(images, labels)\n",
    "                    adv_label_p = victim(x_p).argmax(dim=1)\n",
    "                    adv_label_p = adv_label_p.to('cpu')\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "                    # del TIFGSM_attack\n",
    "\n",
    "                    equality_tensor_p = (labels != adv_label_p).int()\n",
    "                    row+=int(equality_tensor_p.sum())\n",
    "               print(row/1000)\n",
    "               results.append(row/1000)\n",
    "\n",
    "               # with open('timi_results/'+name_v+'_'+name_g+'_'+str(e)+'.pkl', 'wb') as f:\n",
    "               #   pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "022f93f2-4889-4327-9a70-1e1c88de1912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(equality_tensor_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b5d2346-0ce8-428c-81aa-6d1221704e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________\n",
      "Victim: vit_b_16\n",
      "12.75\n",
      "g: efficientnet_b0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [19:17<00:00,  5.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36, 41, 64]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [14:59<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75, 88, 126]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [18:57<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108, 138, 190]\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [16:05<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139, 173, 249]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [17:57<00:00,  5.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[168, 212, 307]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [17:20<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210, 261, 378]\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [15:21<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[251, 301, 443]\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [18:34<00:00,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[285, 342, 496]\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [15:51<00:00,  4.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[313, 383, 557]\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [15:28<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[355, 432, 622]\n",
      "[[355, 432, 622]]\n",
      "g: swin_s\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [30:58<00:00,  9.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 63, 75]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [31:09<00:00,  9.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102, 118, 145]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [30:57<00:00,  9.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149, 177, 216]\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [30:54<00:00,  9.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197, 238, 288]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [30:53<00:00,  9.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[241, 293, 362]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [31:06<00:00,  9.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[282, 345, 435]\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [31:43<00:00,  9.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[344, 415, 515]\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [29:59<00:00,  9.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[390, 474, 594]\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [29:53<00:00,  8.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[444, 542, 668]\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [30:17<00:00,  9.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[484, 604, 744]\n",
      "[[355, 432, 622], [484, 604, 744]]\n",
      "g: densenet121\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [21:28<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 29, 43]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [21:33<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 51, 85]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [21:31<00:00,  6.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55, 87, 138]\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [21:32<00:00,  6.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75, 111, 194]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [21:09<00:00,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103, 146, 248]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [21:23<00:00,  6.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[129, 178, 300]\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [20:33<00:00,  6.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149, 207, 344]\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [19:52<00:00,  5.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175, 242, 400]\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [20:47<00:00,  6.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198, 266, 450]\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [21:18<00:00,  6.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227, 302, 495]\n",
      "[[355, 432, 622], [484, 604, 744], [227, 302, 495]]\n",
      "g: resnet18\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [15:23<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 28, 45]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [16:09<00:00,  4.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 57, 89]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [16:02<00:00,  4.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 82, 132]\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [16:40<00:00,  5.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 116, 186]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [15:21<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96, 136, 215]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [16:03<00:00,  4.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115, 155, 250]\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [16:14<00:00,  4.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 180, 298]\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [16:38<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137, 207, 344]\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [15:43<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[145, 237, 387]\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [16:23<00:00,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165, 261, 436]\n",
      "[[355, 432, 622], [484, 604, 744], [227, 302, 495], [165, 261, 436]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#using torchatacks\n",
    "for i , (name_v, model_v, weights_v) in enumerate(models): \n",
    "    if i!=0:\n",
    "        break\n",
    "    victim = model_v(weights=weights_v.DEFAULT)\n",
    "    print(\"______________________\")\n",
    "    print(\"Victim: \"+ name_v)\n",
    "\n",
    "    S = models.copy()\n",
    "    S.pop(i)\n",
    "    victim = model_with_normalization(victim, normalization)\n",
    "    victim.eval()\n",
    "    victim = victim.to(device)\n",
    "    \n",
    "    with open('../data_'+name_v+'1000images.pkl', 'rb') as f:\n",
    "        new_data_loader = pickle.load(f)\n",
    "\n",
    "    #new_data_loader = DataLoader(new_data_loader.dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    print(e)\n",
    "    for j , (name_g,model_g, weights_g) in enumerate(S):\n",
    "               row = [0,0,0]\n",
    "               print(\"g: \"+ name_g) \n",
    "               g = model_g(weights=weights_g.DEFAULT) \n",
    "               Se = S.copy()\n",
    "               Se.pop(j)\n",
    "               g = model_with_normalization(g, normalization)\n",
    "\n",
    "               g.eval()\n",
    "               g = g.to(device)\n",
    "               \n",
    "               TIFGSM_attack = TIFGSM(g, eps=e/255, alpha=0.3/255, steps=20, random_start=True)\n",
    "                \n",
    "               for batch , (images, labels) in enumerate(new_data_loader):\n",
    "                   print(batch)\n",
    "                   victim = victim.to(device)\n",
    "                   x_p = TIFGSM_attack(images, labels)\n",
    "                   adv_label_p = victim(x_p).argmax(dim=1)\n",
    "                   adv_label_p = adv_label_p.to('cpu')\n",
    "                   equality_tensor_p = (labels != adv_label_p).int()\n",
    "                   row[0]+=int(equality_tensor_p.sum())\n",
    "                \n",
    "                \n",
    "                   augmentations_confidences = []\n",
    "                   augmentations_success = [] \n",
    "\n",
    "\n",
    "#                    print(batch)\n",
    "\n",
    "#                    if batch==10:\n",
    "#                         break\n",
    "                    #mix_ranking\n",
    "                   for _ in tqdm(range(200)):\n",
    "                        victim = victim.to(device)\n",
    "\n",
    "\n",
    "                        #mixing augmentations\n",
    "                        x_a = augmentations(images)\n",
    "                        x_a = TIFGSM_attack(x_a, labels)\n",
    "                        confidance = victim(x_a).softmax(dim=1)\n",
    "                        #conf = confidance[torch.arange(confidance.size(0)),labels].detach().cpu().numpy()\n",
    "                        #conf = conf.to('cpu')\n",
    "\n",
    "                        adv_label_a = confidance.argmax(dim=1)\n",
    "                        adv_label_a = adv_label_a.to('cpu')\n",
    "                        del confidance\n",
    "\n",
    "                        # #one augmentation\n",
    "                        # x_o = random.choice(trans)(images)\n",
    "                        # x_o = PGD_attack(x_o, labels)\n",
    "                        # adv_label_o = victim(x_o).argmax(dim=1)\n",
    "                        # adv_label_o = adv_label_o.to('cpu')\n",
    "\n",
    "                        torch.cuda.empty_cache()\n",
    "                        # del PGD_attack\n",
    "                        victim = victim.to('cpu')\n",
    "\n",
    "                        # average_confidences_p =  np.zeros(batch_size, dtype=np.float32)\n",
    "                        average_confidences_a =  np.zeros(batch_size, dtype=np.float32)\n",
    "                        # average_confidences_o =  np.zeros(batch_size, dtype=np.float32)\n",
    "                        for n , model_s, weights_s in Se:\n",
    "\n",
    "                            model = model_s(weights=weights_s.DEFAULT)\n",
    "                            model = model.to(device)\n",
    "                            model = model_with_normalization(model, normalization)\n",
    "                            model.eval()\n",
    "\n",
    "#                                 outputs_p = model(x_p).softmax(dim=1)\n",
    "#                                 confidences_p = outputs_p[torch.arange(outputs_p.size(0)),labels].detach().cpu().numpy()\n",
    "#                                 average_confidences_p += confidences_p\n",
    "#                                 del outputs_p,confidences_p\n",
    "\n",
    "\n",
    "                            outputs_a = model(x_a).softmax(dim=1)\n",
    "                            confidences_a = outputs_a[torch.arange(outputs_a.size(0)),labels].detach().cpu().numpy()                            \n",
    "                            average_confidences_a += confidences_a\n",
    "                            del outputs_a,confidences_a\n",
    "\n",
    "\n",
    "#                                 outputs_o = model(x_o).softmax(dim=1)\n",
    "#                                 confidences_o = outputs_o[torch.arange(outputs_o.size(0)),labels].detach().cpu().numpy()                            \n",
    "#                                 average_confidences_o += confidences_o\n",
    "\n",
    "#                                 # outputs_o = outputs_o.to('cpu')\n",
    "#                                 # model = model.to('cpu')\n",
    "#                                 del outputs_o,confidences_o,model\n",
    "#                                 # # del confidences_o\n",
    "                            # del model\n",
    "\n",
    "\n",
    "                            torch.cuda.empty_cache()\n",
    "                        del x_a#x_p,x_a,x_o\n",
    "\n",
    "\n",
    "\n",
    "                        # average_confidences_p /= len(Se)\n",
    "                        average_confidences_a /= len(Se)\n",
    "                        # average_confidences_o /= len(Se)\n",
    "\n",
    "                        # equality_tensor_p = (labels != adv_label_p).int()\n",
    "                        equality_tensor_a = (labels != adv_label_a).int() \n",
    "                        # equality_tensor_o = (labels != adv_label_o).int()\n",
    "\n",
    "\n",
    "\n",
    "                        # confidences.append(conf)\n",
    "\n",
    "#                             perturbation_confidences.append(average_confidences_p)\n",
    "#                             perturbation_success.append(equality_tensor_p)\n",
    "                        augmentations_confidences.append(average_confidences_a)\n",
    "                        augmentations_success.append(equality_tensor_a)\n",
    "                        # augmentation_confidences.append(average_confidences_o)\n",
    "                        # augmentation_success.append(equality_tensor_o)\n",
    "\n",
    "                        torch.cuda.empty_cache()\n",
    "                   # merged_results_p = [tuple(zip(np.array(perturbation_confidences)[:, i], torch.stack(perturbation_success).numpy()[:, i]))\n",
    "                   #      for i in range(batch_size)]\n",
    "\n",
    "                   # merged_results_a = [tuple(zip(np.array(augmentations_confidences)[:, i], torch.stack(augmentations_success).numpy()[:, i]))\n",
    "                   #      for i in range(batch_size)]\n",
    "                   merged_results_a = [tuple(zip(np.array(augmentations_confidences)[:, i], torch.stack(augmentations_success).numpy()[:, i])) for i in range(batch_size)]\n",
    "\n",
    "\n",
    "\n",
    "                   # merged_results_o = [tuple(zip(np.array(augmentation_confidences)[:, i], torch.stack(augmentation_success).numpy()[:, i]))\n",
    "                   #      for i in range(batch_size)]\n",
    "\n",
    "                    # Sort the merged results based on the mean confidence for each image\n",
    "                   # sorted_results_p = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_p]\n",
    "                   #sorted_results_a = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_a]\n",
    "                   # sorted_results_o = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_o]\n",
    "\n",
    "                   sorted_results_a = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_a]\n",
    "\n",
    "\n",
    "                   # best_result = 0\n",
    "                   # random_result = 0\n",
    "                   # for sublist in sorted_results_p:\n",
    "                   #      # Increment the best result based on the first item's binary value\n",
    "                   #      best_result += sublist[0][1]\n",
    "                   #      # Calculate the sum of random items in each sublist\n",
    "                   #      random_result += random.choice(sublist)[1]\n",
    "\n",
    "#                        row[0]+=random_result\n",
    "#                        row[1]+=best_result\n",
    "\n",
    "#                        best_result = 0\n",
    "#                        random_result = 0 \n",
    "#                        for sublist in sorted_results_o:\n",
    "#                             # Increment the best result based on the first item's binary value\n",
    "#                             best_result += sublist[0][1]\n",
    "#                             # Calculate the sum of random items in each sublist\n",
    "#                             random_result += random.choice(sublist)[1]\n",
    "#                        row[2]+=random_result\n",
    "#                        row[3]+=best_result\n",
    "\n",
    "\n",
    "\n",
    "                   best_result = 0\n",
    "                   random_result = 0 \n",
    "                   # best_v = 0\n",
    "                   for sublist in sorted_results_a:\n",
    "\n",
    "                        best_result += sublist[0][1]\n",
    "                        # best_v += min(sublist, key=lambda x: x[1])[2]\n",
    "                        # Increment the best result based on the first item's binary value\n",
    "                        #best_result += sublist[0][1]\n",
    "                        # Calculate the sum of random items in each sublist\n",
    "                        random_result += random.choice(sublist)[1]\n",
    "\n",
    "                   # print(\"Best Result(augmentations):\", best_result)\n",
    "                   # print(\"Random Result(augmentations):\", random_result) \n",
    "                   # results_a[(name_v,name_g)][0]+= best_result\n",
    "                   # results_a[(name_v,name_g)][1]+= random_result\n",
    "\n",
    "                   row[1]+=random_result\n",
    "                   row[2]+=best_result\n",
    "                   # row[6]+=best_v\n",
    "                   print(row) \n",
    "                   # upperB[(name_v,name_g)] += best_v  \n",
    "                   # print(results_a)     \n",
    "                   # print(upperB)  \n",
    "                   del images, labels\n",
    "                   torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "               results.append(row)\n",
    "               print(results)\n",
    "               del g\n",
    "               with open('results_timi/'+name_v+'_'+name_g+'_'+str(e)+'.pkl', 'wb') as f:\n",
    "                 pickle.dump(results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c845662-748e-44c7-b398-7a99ab5464f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"vit_b_16\",\"efficientnet_b0\",\"swin_s\",\"densenet121\",\"resnet18\"]\n",
    "table_e = []\n",
    "for i , name_v in enumerate(models):\n",
    "    S = models.copy()\n",
    "    S.pop(i)        \n",
    "    for j , name_g in enumerate(S):\n",
    "        # print(j)\n",
    "        if (i==0 or i==1 or i==2)  and j==3:\n",
    "             with open('results_timi/'+name_v+'_'+name_g+'_'+str(e)+'.pkl', 'rb') as f:\n",
    "                             results = pickle.load(f)\n",
    "                             table_e+=results\n",
    "        elif i==4 and j==2:\n",
    "             with open('results_timi/'+name_v+'_'+name_g+'_'+str(e)+'.pkl', 'rb') as f:\n",
    "                             results = pickle.load(f)\n",
    "                             table_e+=results\n",
    "        elif i==3 and j==3:\n",
    "             with open('results_timi/'+name_v+'_'+name_g+'_'+str(e)+'.pkl', 'rb') as f:\n",
    "                             results = pickle.load(f)\n",
    "                             table_e+=results\n",
    "\n",
    "table_e = [[item / 1000 for item in sublist] for sublist in table_e]\n",
    "\n",
    "# with open('tables/table_'+str(e)+'.pkl', 'wb') as f:\n",
    "#                  pickle.dump(table_e, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff112a9-df24-4d3e-b7a6-b300cc1e11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f245e-805b-4c80-b932-ac64f6c7303d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEST_GPU",
   "language": "python",
   "name": "test_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
