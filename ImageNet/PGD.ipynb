{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d5aa27-12e1-43e7-9eca-84a811b826ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baravrah/.conda/envs/gpu_test/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/baravrah/.conda/envs/gpu_test/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/baravrah/.conda/envs/gpu_test/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "# from art.attacks.evasion import ProjectedGradientDescentPyTorch\n",
    "from torchattacks import PGD\n",
    "from art.utils import random_sphere\n",
    "from art.config import ART_NUMPY_DTYPE\n",
    "import numpy as np\n",
    "from torchvision.transforms import v2\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights, vgg19 , VGG19_Weights, resnet18, ResNet18_Weights, densenet121,  densenet121, DenseNet121_Weights, vit_b_16, ViT_B_16_Weights, efficientnet_b2, EfficientNet_B2_Weights,  swin_s, Swin_S_Weights, convnext_base, ConvNeXt_Base_Weights, squeezenet1_0, SqueezeNet1_0_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff6c684-39c6-487b-9f49-6cac58bf103d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'570820'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['SLURM_JOBID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c49aec-a35a-48a8-a12f-6c808129853e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4049f8-efa8-428e-9ad1-edd186f741e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [(\"vit_b_16\",vit_b_16, ViT_B_16_Weights),\n",
    "          (\"efficientnet_b0\" , efficientnet_b0, EfficientNet_B0_Weights),\n",
    "          (\"swin_s\", swin_s, Swin_S_Weights),\n",
    "          (\"densenet121\" , densenet121, DenseNet121_Weights),\n",
    "          (\"resnet18\" ,resnet18, ResNet18_Weights)]\n",
    "            # (\"convnext_base\", convnext_base,ConvNeXt_Base_Weights)]\n",
    "         # (\"squeezenet1_0\",squeezenet1_0, SqueezeNet1_0_Weights)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4b4ba-081d-4d82-98ae-4a64f4bdf6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbacab9c-19b5-4c8b-919a-e812f394826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_with_normalization(nn.Module):\n",
    "    def __init__(self, model, normalization):\n",
    "        super(model_with_normalization, self).__init__()\n",
    "        self.model = model \n",
    "        self.normalization = normalization\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.normalization(x)\n",
    "        if x.shape == (3,224,224):\n",
    "          x = x.unsqueeze(0)\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "normalization = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85c398-5f55-4665-9605-1c8188208474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Initialize your custom dataset\n",
    "# new_dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d072519-9255-409b-86bd-de643cf905d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_image(image_path):\n",
    "    return Image.open(image_path).convert('RGB')  # Ensure the image is in RGB format\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1080b-b14c-4713-a3ef-86bc9e2d558b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from torch.cuda.amp import autocast\n",
    "trans = [\n",
    "    transforms.RandomAffine(degrees=(-2, 2), translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomCrop(size=(224, 224), padding=10),\n",
    "    transforms.GaussianBlur(kernel_size=3),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2,p=1),\n",
    "    transforms.RandomAutocontrast(1)]\n",
    "\n",
    "\n",
    "augmentations = transforms.Compose(trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acfa34f-4a91-4cca-9a4d-4d12e0512b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "batch_size = 100\n",
    "d = {}\n",
    "for i , (name_v, model_v, weights_v) in enumerate(models): \n",
    "        victim = model_v(weights=weights_v.DEFAULT)\n",
    "        print(\"______________________\")\n",
    "        print(\"Victim: \"+ name_v)\n",
    "    \n",
    "        S = models.copy()\n",
    "        S.pop(i)\n",
    "        victim = model_with_normalization(victim, normalization)\n",
    "        victim.eval()\n",
    "        victim = victim.to(device)\n",
    "        \n",
    "        with open('../data_'+name_v+'1000images.pkl', 'rb') as f:\n",
    "            new_data_loader = pickle.load(f)\n",
    "    \n",
    "        for j , (name_g,model_g, weights_g) in enumerate(S):\n",
    "                       row = [0,0,0]\n",
    "                       print(\"g: \"+ name_g) \n",
    "                       g = model_g(weights=weights_g.DEFAULT) \n",
    "                       Se = S.copy()\n",
    "                       Se.pop(j)\n",
    "                       g = model_with_normalization(g, normalization)\n",
    "                       g.eval()\n",
    "                       g = g.to(device)\n",
    "                       ASR = 0\n",
    "                       total_l2_score = 0\n",
    "            \n",
    "                       for batch , (images, labels) in enumerate(new_data_loader):\n",
    "                           print(batch)\n",
    "                           labels =labels.to(device)\n",
    "                           #PGN\n",
    "                           PGD_attack = PGD(g, eps=12.75/255, alpha=random.uniform(0.1/255, 0.3/255), steps =random.randint(10, 20), random_start=True)\n",
    "                           x_p = PGD_attack(images, labels)\n",
    "                           adv_label_p = victim(x_p).argmax(dim=1)\n",
    "                           # adv_label_p = adv_label_p.to('cpu')\n",
    "                           ASR += (labels != adv_label_p).int().sum().item()\n",
    "                           #print(ASR)\n",
    "                           l2_score = torch.norm(images - x_p)\n",
    "                           total_l2_score += l2_score.sum().item()\n",
    "                           #print(l2_score)\n",
    "            \n",
    "                       d[f'{name_v}_{name_g}_ASR'] = ASR/1000\n",
    "                       d[f'{name_v}_{name_g}_L2'] = total_l2_score/1000\n",
    "                       print(ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70804d-d59c-459f-bee2-b4ad756b685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ranking_simba_baselines/PGD.pkl', 'wb') as f:\n",
    "     pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f18142-3e55-4cb9-bb93-f146d8522782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pgd_attack(S, images, labels, eps=0.3, alpha=2/255, iters=40) :\n",
    "#     images = images.to(device)\n",
    "#     labels = labels.to(device)\n",
    "#     loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "#     ori_images = images.data\n",
    "        \n",
    "#     for i in range(iters) :\n",
    "#         cost = 0\n",
    "#         images.requires_grad = True\n",
    "#         for j , (name_g,model_g, weights_g) in enumerate(S):\n",
    "#             g = model_g(weights=weights_g.DEFAULT)\n",
    "#             g = model_with_normalization(g, normalization)\n",
    "#             g.eval()\n",
    "#             g = g.to(device)\n",
    "  \n",
    "#             outputs = g(images)\n",
    "#             g.zero_grad()\n",
    "#             cost+= loss(outputs, labels).to(device)\n",
    "#             del g\n",
    "\n",
    "        \n",
    "#         cost.backward()\n",
    "\n",
    "#         adv_images = images + alpha*images.grad.sign()\n",
    "#         eta = torch.clamp(adv_images - ori_images, min=-eps, max=eps)\n",
    "#         images = torch.clamp(ori_images + eta, min=0, max=1).detach_()\n",
    "\n",
    "    \n",
    "#     return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7bf1eda-ba55-4fb8-95bb-8e4367f4b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 100\n",
    "\n",
    "# for i , (name_v, model_v, weights_v) in enumerate(models): \n",
    "#     victim = model_v(weights=weights_v.DEFAULT)\n",
    "#     print(\"______________________\")\n",
    "#     print(\"Victim: \"+ name_v)\n",
    "\n",
    "#     S = models.copy()\n",
    "#     S.pop(i)\n",
    "#     victim = model_with_normalization(victim, normalization)\n",
    "#     victim.eval()\n",
    "#     victim = victim.to(device)\n",
    "#     total_ASR = 0\n",
    "#     with open('../data_'+name_v+'1000images.pkl', 'rb') as f:\n",
    "#         new_data_loader = pickle.load(f)\n",
    "\n",
    "#     e = 3   \n",
    "#     for batch , (images, labels) in enumerate(new_data_loader):\n",
    "#        labels = labels.to(device)\n",
    "#        x_p = pgd_attack(S, images, labels, eps=e/255, alpha=0.3/255, iters=20)\n",
    "#        adv_label_p = victim(x_p).argmax(dim=1)\n",
    "#        # adv_label_p = adv_label_p.to('cpu')\n",
    "#        ASR = (labels != adv_label_p).int().sum().item()\n",
    "#        print(ASR)\n",
    "#        total_ASR+=ASR\n",
    "#     print(total_ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66f91c09-b4de-4b4b-ba0f-950aa8ae69fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import mnasnet1_0, MNASNet1_0_Weights, efficientnet_b0,regnet_x_800mf, RegNet_X_800MF_Weights, EfficientNet_B0_Weights, vgg19 , VGG19_Weights, resnet18, ResNet18_Weights, densenet121,  densenet121, DenseNet121_Weights, vit_b_16, ViT_B_16_Weights, efficientnet_b2, EfficientNet_B2_Weights,  swin_s, Swin_S_Weights, convnext_base, ConvNeXt_Base_Weights, squeezenet1_0, SqueezeNet1_0_Weights\n",
    "# S2 = [ (\"convnext_base\", convnext_base,ConvNeXt_Base_Weights),\n",
    "#        (\"squeezenet1_0\",squeezenet1_0, SqueezeNet1_0_Weights),\n",
    "#       (\"mnasnet1_0\",mnasnet1_0, MNASNet1_0_Weights),\n",
    "#       (\"regnet_x_800mf\", regnet_x_800mf, RegNet_X_800MF_Weights)\n",
    "#      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "031334c8-775e-4f61-8d0d-a8311c6aff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "e=25.5\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3302c699-9d7e-4677-a0f5-d56d25ccef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #using torchatacks\n",
    "\n",
    "# batch_size = 100\n",
    "# for i , (name_v, model_v, weights_v) in enumerate(models): \n",
    "#     if i == 0:\n",
    "#         continue\n",
    "#     if i>1:\n",
    "#         break\n",
    "#     victim = model_v(weights=weights_v.DEFAULT)\n",
    "#     print(\"______________________\")\n",
    "#     print(\"Victim: \"+ name_v)\n",
    "\n",
    "#     S = models.copy()\n",
    "#     S.pop(i)\n",
    "#     victim = model_with_normalization(victim, normalization)\n",
    "#     victim.eval()\n",
    "#     victim = victim.to(device)\n",
    "    \n",
    "#     with open('../data_'+name_v+'1000images.pkl', 'rb') as f:\n",
    "#         new_data_loader = pickle.load(f)\n",
    "\n",
    "#     new_data_loader = DataLoader(\n",
    "#             new_data_loader.dataset, batch_size=batch_size, shuffle=True #[x:x+100]\n",
    "#         )\n",
    "    \n",
    "#     row = [0,0]\n",
    "#     for j , (name_g,model_g, weights_g) in enumerate(S):\n",
    "#            if j!=0:\n",
    "#                 break\n",
    "#            print(\"g: \"+ name_g) \n",
    "#            g = model_g(weights=weights_g.DEFAULT) \n",
    "#            Se = S.copy()\n",
    "#            Se.pop(j)\n",
    "#            g = model_with_normalization(g, normalization)\n",
    "\n",
    "#            g.eval()\n",
    "#            g = g.to(device)\n",
    "#            ASR = 0\n",
    "#            for batch , (images, labels) in enumerate(new_data_loader):\n",
    "#                    labels =labels.to(device)\n",
    "#                    images = images.to(device)\n",
    "#                    augmentations_confidences = []\n",
    "#                    augmentations_success = []\n",
    "#                    # x_p = PGD(g, eps=e/255, alpha=0.3/255, steps = 20 , random_start=True)\n",
    "\n",
    "#                    # PGD_attack = PGD(g, eps=e/255, alpha=random.uniform(0.1/255, 0.3/255), steps =random.randint(10, 20), random_start=True)\n",
    "\n",
    "\n",
    "#                    #  #random pertubations\n",
    "#                    # x_p = PGD_attack(images, labels)\n",
    "#                    # adv_label_p = victim(x_p).argmax(dim=1)\n",
    "#                    # # adv_label_p = adv_label_p.to('cpu')\n",
    "               \n",
    "#                    # # adv_label_p = victim(x_p).argmax(dim=1)\n",
    "#                    # ASR += (labels != adv_label_p).int().sum().item()\n",
    "#                    # print(ASR)\n",
    "\n",
    "\n",
    "           \n",
    "#        #     for _ in tqdm(range(200)):\n",
    "#        #          victim = victim.to(device)\n",
    "#        #          # mixing augmentations\n",
    "#        #          x_a = augmentations(images)\n",
    "#        #          # images_min = clip_by_tensor(x_a - 12.75 / 255.0, 0.0, 1.0)\n",
    "#        #          # images_max = clip_by_tensor(x_a + 12.75 / 255.0, 0.0, 1.0)\n",
    "#        #          x_a = pgd_attack(S2, images, labels, eps=e/255, alpha=0.3/255, iters=20)\n",
    "#        #          confidance = victim(x_a).softmax(dim=1)\n",
    "#        #          conf = confidance[torch.arange(confidance.size(0)),labels].detach().cpu().numpy()\n",
    "#        #          adv_label_a = confidance.argmax(dim=1)\n",
    "#        #          # adv_label_a = adv_label_a.to('cpu')\n",
    "#        #          del confidance\n",
    "\n",
    "#        #          torch.cuda.empty_cache()\n",
    "#        #          # del PGD_attack\n",
    "#        #          victim = victim.to('cpu')\n",
    "\n",
    "#        #          # average_confidences_p =  np.zeros(batch_size, dtype=np.float32)\n",
    "#        #          average_confidences_a =  np.zeros(batch_size, dtype=np.float32)\n",
    "#        #          # average_confidences_o =  np.zeros(batch_size, dtype=np.float32)\n",
    "#        #          for n , model_s, weights_s in S:\n",
    "\n",
    "#        #              model = model_s(weights=weights_s.DEFAULT)\n",
    "#        #              model = model.to(device)\n",
    "#        #              model = model_with_normalization(model, normalization)\n",
    "#        #              model.eval()\n",
    "\n",
    "#        #              outputs_a = model(x_a).softmax(dim=1)\n",
    "#        #              confidences_a = outputs_a[torch.arange(outputs_a.size(0)),labels].detach().cpu().numpy()                            \n",
    "#        #              average_confidences_a += confidences_a\n",
    "#        #              del outputs_a,confidences_a\n",
    "#        #              del model\n",
    "\n",
    "\n",
    "#        #              torch.cuda.empty_cache()\n",
    "#        #          del x_a#x_p,x_a,x_o\n",
    "\n",
    "#        #          average_confidences_a /= len(S)\n",
    "#        #          equality_tensor_a = (labels != adv_label_a).int() \n",
    "\n",
    "#        #          augmentations_confidences.append(average_confidences_a)\n",
    "#        #          augmentations_success.append(equality_tensor_a)\n",
    "#        #          torch.cuda.empty_cache()\n",
    "       \n",
    "#        #     merged_results_a = [\n",
    "#        #                          tuple(\n",
    "#        #                              zip(\n",
    "#        #                                  np.array(augmentations_confidences)[:, i],\n",
    "#        #                                  torch.stack(augmentations_success).cpu().numpy()[:, i]\n",
    "#        #                              )\n",
    "#        #                          ) \n",
    "#        #                          for i in range(batch_size)\n",
    "#        #                      ]\n",
    "\n",
    "\n",
    "#        #     # merged_results_o = [tuple(zip(np.array(augmentation_confidences)[:, i], torch.stack(augmentation_success).numpy()[:, i]))\n",
    "#        #     #      for i in range(batch_size)]\n",
    "\n",
    "#        #      # Sort the merged results based on the mean confidence for each image\n",
    "#        #     # sorted_results_p = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_p]\n",
    "#        #     #sorted_results_a = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_a]\n",
    "#        #     # sorted_results_o = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_o]\n",
    "\n",
    "#        #     sorted_results_a = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_a]\n",
    "\n",
    "        \n",
    "\n",
    "#        #     best_result = 0\n",
    "#        #     random_result = 0 \n",
    "#        #     best_v = 0\n",
    "#        #     for sublist in sorted_results_a:\n",
    "\n",
    "#        #          best_result += sublist[0][1]\n",
    "#        #          random_result += random.choice(sublist)[1]\n",
    "\n",
    "\n",
    "#        #     row[0]+=random_result\n",
    "#        #     row[1]+=best_result\n",
    "#        #     # row[6]+=best_v\n",
    "#        #     print(row) \n",
    "#        #     del images, labels\n",
    "#        #     torch.cuda.empty_cache()\n",
    "#        # print(row)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e34afee-c4ed-4f6c-ac68-ea8267dc62ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\"vit_b_16\",\"efficientnet_b0\",\"swin_s\",\"densenet121\",\"resnet18\"]\n",
    "# eps = [2, 4, 6, 8, 10, 12.75 , 14, 16, 18, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb2fe84c-4343-4d54-8775-7a18d2e51271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in eps:\n",
    "#     table_e = []\n",
    "#     for i , name_v in enumerate(models):\n",
    "#         S = models.copy()\n",
    "#         S.pop(i)        \n",
    "#         for j , name_g in enumerate(S):\n",
    "#             # print(j)\n",
    "#             if j==3:\n",
    "#                  with open(name_v+'_'+name_g+'_'+str(e)+'.pkl', 'rb') as f:\n",
    "#                                  results = pickle.load(f)\n",
    "#                                  table_e+=results\n",
    "\n",
    "#     table_e = [[item / 1000 for item in sublist] for sublist in table_e]\n",
    "\n",
    "#     with open('tables/table_'+str(e)+'.pkl', 'wb') as f:\n",
    "#                      pickle.dump(table_e, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a6eb5d3-beb1-467b-9e5d-f42a6be586f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________\n",
      "Victim: efficientnet_b0\n",
      "g: vit_b_16\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [29:12<00:00,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 50, 65, 0]\n",
      "g: swin_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "batch_size =100\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore', category=Warning)\n",
    "\n",
    "for i , (name_v, model_v, weights_v) in enumerate(models): \n",
    "    if i == 0:\n",
    "        continue\n",
    "    if i>1:\n",
    "        break\n",
    "    victim = model_v(weights=weights_v.DEFAULT)\n",
    "    print(\"______________________\")\n",
    "    print(\"Victim: \"+ name_v)\n",
    "\n",
    "    S = models.copy()\n",
    "    S.pop(i)\n",
    "    victim = model_with_normalization(victim, normalization)\n",
    "    victim.eval()\n",
    "    victim = victim.to(device)\n",
    "    \n",
    "    with open('../data_'+name_v+'1000images.pkl', 'rb') as f:\n",
    "        new_data_loader = pickle.load(f)\n",
    "\n",
    "    new_data_loader = DataLoader(\n",
    "            new_data_loader.dataset[x:x+100], batch_size=batch_size, shuffle=True #[x:x+100]\n",
    "        )\n",
    "\n",
    "    for j , (name_g,model_g, weights_g) in enumerate(S):\n",
    "                   row = [0,0,0,0,0,0,0]\n",
    "                   print(\"g: \"+ name_g)\n",
    "                   if j>0:\n",
    "                       break\n",
    "                    \n",
    "                   g = model_g(weights=weights_g.DEFAULT) \n",
    "                   Se = S.copy()\n",
    "                   Se.pop(j)\n",
    "                   g = model_with_normalization(g, normalization)\n",
    "\n",
    "                   g.eval()\n",
    "                   g = g.to(device)\n",
    "                   for batch , (images, labels) in enumerate(new_data_loader):\n",
    "                       perturbation_confidences = []\n",
    "                       perturbation_success = []\n",
    "\n",
    "                       augmentations_confidences = []\n",
    "                       augmentations_success = []\n",
    "\n",
    "                       augmentation_confidences = []\n",
    "                       augmentation_success = [] \n",
    "\n",
    "                       confidences = []\n",
    "                       print(batch)\n",
    "                       for _ in tqdm(range(200)):\n",
    "                            victim = victim.to(device)\n",
    "                            PGD_attack = PGD(g, eps=e/255, alpha=random.uniform(0.1/255, 0.3/255), steps =random.randint(10, 20), random_start=True)\n",
    "\n",
    "\n",
    "                            # #random pertubations\n",
    "                            # x_p = PGD_attack(images, labels)\n",
    "                            # adv_label_p = victim(x_p).argmax(dim=1)\n",
    "                            # adv_label_p = adv_label_p.to('cpu')\n",
    "\n",
    "                            #mixing augmentations\n",
    "                            x_a = augmentations(images)\n",
    "                            x_a = PGD_attack(x_a, labels)\n",
    "                            confidance = victim(x_a).softmax(dim=1)\n",
    "                            conf = confidance[torch.arange(confidance.size(0)),labels].detach().cpu().numpy()\n",
    "                            #conf = conf.to('cpu')\n",
    "\n",
    "                            adv_label_a = confidance.argmax(dim=1)\n",
    "                            adv_label_a = adv_label_a.to('cpu')\n",
    "                            del confidance\n",
    "\n",
    "                            # #one augmentation\n",
    "                            # x_o = random.choice(trans)(images)\n",
    "                            # x_o = PGD_attack(x_o, labels)\n",
    "                            # adv_label_o = victim(x_o).argmax(dim=1)\n",
    "                            # adv_label_o = adv_label_o.to('cpu')\n",
    "\n",
    "                            torch.cuda.empty_cache()\n",
    "                            del PGD_attack\n",
    "                            victim = victim.to('cpu')\n",
    "\n",
    "                            # average_confidences_p =  np.zeros(batch_size, dtype=np.float32)\n",
    "                            average_confidences_a =  np.zeros(batch_size, dtype=np.float32)\n",
    "                            # average_confidences_o =  np.zeros(batch_size, dtype=np.float32)\n",
    "                            for n , model_s, weights_s in Se:\n",
    "\n",
    "                                model = model_s(weights=weights_s.DEFAULT)\n",
    "                                model = model.to(device)\n",
    "                                model = model_with_normalization(model, normalization)\n",
    "                                model.eval()\n",
    "\n",
    "                                # outputs_p = model(x_p).softmax(dim=1)\n",
    "                                # confidences_p = outputs_p[torch.arange(outputs_p.size(0)),labels].detach().cpu().numpy()\n",
    "                                # average_confidences_p += confidences_p\n",
    "                                # del outputs_p,confidences_p\n",
    "\n",
    "\n",
    "                                outputs_a = model(x_a).softmax(dim=1)\n",
    "                                confidences_a = outputs_a[torch.arange(outputs_a.size(0)),labels].detach().cpu().numpy()                            \n",
    "                                average_confidences_a += confidences_a\n",
    "                                del outputs_a,confidences_a\n",
    "\n",
    "\n",
    "                                # outputs_o = model(x_o).softmax(dim=1)\n",
    "                                # confidences_o = outputs_o[torch.arange(outputs_o.size(0)),labels].detach().cpu().numpy()                            \n",
    "                                # average_confidences_o += confidences_o\n",
    "\n",
    "                                # outputs_o = outputs_o.to('cpu')\n",
    "                                # model = model.to('cpu')\n",
    "                                # del outputs_o,confidences_o,model\n",
    "                                # # del confidences_o\n",
    "                                # del model\n",
    "\n",
    "\n",
    "                                torch.cuda.empty_cache()\n",
    "                            # del x_p,x_a,x_o\n",
    "\n",
    "\n",
    "\n",
    "                            # average_confidences_p /= len(Se)\n",
    "                            average_confidences_a /= len(Se)\n",
    "                            # average_confidences_o /= len(Se)\n",
    "\n",
    "                            # equality_tensor_p = (labels != adv_label_p).int()\n",
    "                            equality_tensor_a = (labels != adv_label_a).int() \n",
    "                            # equality_tensor_o = (labels != adv_label_o).int()\n",
    "\n",
    "\n",
    "\n",
    "                            confidences.append(conf)\n",
    "\n",
    "                            # perturbation_confidences.append(average_confidences_p)\n",
    "                            # perturbation_success.append(equality_tensor_p)\n",
    "                            augmentations_confidences.append(average_confidences_a)\n",
    "                            augmentations_success.append(equality_tensor_a)\n",
    "                            # augmentation_confidences.append(average_confidences_o)\n",
    "                            # augmentation_success.append(equality_tensor_o)\n",
    "\n",
    "                            torch.cuda.empty_cache()\n",
    "                       # merged_results_p = [tuple(zip(np.array(perturbation_confidences)[:, i], torch.stack(perturbation_success).numpy()[:, i]))\n",
    "                       #      for i in range(batch_size)]\n",
    "\n",
    "                       # merged_results_a = [tuple(zip(np.array(augmentations_confidences)[:, i], torch.stack(augmentations_success).numpy()[:, i]))\n",
    "                       #      for i in range(batch_size)]\n",
    "                       merged_results_a = [tuple(zip(np.array(augmentations_confidences)[:, i], np.array(confidences)[:, i], torch.stack(augmentations_success).numpy()[:, i])) for i in range(batch_size)]\n",
    "\n",
    "\n",
    "\n",
    "                       # merged_results_o = [tuple(zip(np.array(augmentation_confidences)[:, i], torch.stack(augmentation_success).numpy()[:, i]))\n",
    "                       #      for i in range(batch_size)]\n",
    "\n",
    "                        # Sort the merged results based on the mean confidence for each image\n",
    "                       # sorted_results_p = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_p]\n",
    "                       #sorted_results_a = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_a]\n",
    "                       # sorted_results_o = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_o]\n",
    "\n",
    "                       sorted_results_a = [sorted(image_results, key=lambda x: x[0], reverse=False) for image_results in merged_results_a]\n",
    "\n",
    "                       \n",
    "                       # best_result = 0\n",
    "                       # random_result = 0\n",
    "                       # for sublist in sorted_results_p:\n",
    "                       #      # Increment the best result based on the first item's binary value\n",
    "                       #      best_result += sublist[0][1]\n",
    "                       #      # Calculate the sum of random items in each sublist\n",
    "                       #      random_result += random.choice(sublist)[1]\n",
    "\n",
    "                       # row[0]+=random_result\n",
    "                       # row[1]+=best_result\n",
    "\n",
    "                       # best_result = 0\n",
    "                       # random_result = 0 \n",
    "                       # for sublist in sorted_results_o:\n",
    "                       #      # Increment the best result based on the first item's binary value\n",
    "                       #      best_result += sublist[0][1]\n",
    "                       #      # Calculate the sum of random items in each sublist\n",
    "                       #      random_result += random.choice(sublist)[1]\n",
    "                       # row[2]+=random_result\n",
    "                       # row[3]+=best_result\n",
    "\n",
    "\n",
    "                       best_result = 0\n",
    "                       random_result = 0 \n",
    "                       best_v = 0\n",
    "                       for sublist in sorted_results_a:\n",
    "\n",
    "                            best_result += sublist[0][2]\n",
    "                            # best_v += min(sublist, key=lambda x: x[1])[2]\n",
    "                            # Increment the best result based on the first item's binary value\n",
    "                            #best_result += sublist[0][1]\n",
    "                            # Calculate the sum of random items in each sublist\n",
    "                            random_result += random.choice(sublist)[2]\n",
    "\n",
    "                       row[4]+=random_result\n",
    "                       row[5]+=best_result\n",
    "                       # row[6]+=best_v\n",
    "                       print(row) \n",
    "                       # upperB[(name_v,name_g)] += best_v  \n",
    "                       # print(results_a)     \n",
    "                       # print(upperB)  \n",
    "                       del images, labels\n",
    "                       torch.cuda.empty_cache()\n",
    "                        \n",
    "\n",
    "                   del g\n",
    "                   with open('BTA_PEAS/'+name_v+'_'+name_g+'_'+str(e)+'_'+str(x)+ '.pkl', 'wb') as f:\n",
    "                     pickle.dump(row, f)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61f7cb-17ba-4597-8f5d-89ab8b77dd79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEST_GPU",
   "language": "python",
   "name": "test_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
