{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#PEAS\n",
        "\n",
        "This notebook demonstrates how to enhance baseline transfer attacks using the PEAS.\n",
        "\n",
        "**Overview:**\n",
        "\n",
        "In this notebook, you will find:\n",
        "* PEAS Class Implementation: Define and utilize the PEAS class to generate adversarial examples under different augmentation scenarios.\n",
        "\n",
        "* Parameter Definitions: Set up victim and substitute models, augmentation techniques, and attack parameters.\n",
        "\n",
        "* Dataset Preparation: Load and preprocess the CIFAR-10 dataset, selecting correctly classified samples for evaluation.\n",
        "\n",
        "* Baseline Transfer Attack: Define the baseline transfer attack (e.g., PGD) to be boosted by PEAS.\n",
        "\n",
        "* Attack Success Rate (ASR) Calculation: Evaluate the effectiveness of the generated adversarial examples against a victim model.\n",
        "\n",
        "\n",
        "The results will vary slightly between runs due to the random processes (augmentations and selection of images). This notebook has been setup to work on CIFAR-10 and can be adapted to other datasets. It is designed to boost any non-query based attack (e.g., BTA, PGN, TIMI).\n",
        "\n",
        "**Getting Started:**\n",
        "\n",
        "To begin, ensure you have all necessary libraries installed and run the cells in order. You can modify model names, parameters, and transformations as needed to fit your specific requirements. Each section includes detailed comments and explanations to guide you through the process."
      ],
      "metadata": {
        "id": "ufVpC5N_mhOi"
      },
      "id": "ufVpC5N_mhOi"
    },
    {
      "cell_type": "markdown",
      "id": "F18YPiFZ6bR5",
      "metadata": {
        "id": "F18YPiFZ6bR5"
      },
      "source": [
        "##Install and Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "xKRopdkWxoEr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKRopdkWxoEr",
        "outputId": "3ec17305-149e-48f6-f338-4ef2b2b5329f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchattacks\n",
            "  Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/142.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/142.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (0.18.1+cu121)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (4.66.4)\n",
            "Collecting requests~=2.25.1 (from torchattacks)\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.25.2)\n",
            "Collecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.1->torchattacks)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.1->torchattacks)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.1->torchattacks)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.1->torchattacks)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.1->torchattacks)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.1->torchattacks)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.1->torchattacks)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.1->torchattacks)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.1->torchattacks)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.7.1->torchattacks)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.1->torchattacks)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.1->torchattacks)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8.2->torchattacks) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\n",
            "Installing collected packages: urllib3, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, idna, chardet, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchattacks\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.11.1 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.25.1 which is incompatible.\n",
            "tweepy 4.14.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\n",
            "yfinance 0.2.40 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-4.0.0 idna-2.10 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 requests-2.25.1 torchattacks-3.5.1 urllib3-1.26.19\n"
          ]
        }
      ],
      "source": [
        "pip install torchattacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e6413908-2b7e-4e26-90dd-1863993135c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6413908-2b7e-4e26-90dd-1863993135c4",
        "outputId": "710298d6-ea34-406e-9447-488f44da66cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:293: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or list(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use list(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cifar100_mobilenetv2_x0_5',\n",
            " 'cifar100_mobilenetv2_x0_75',\n",
            " 'cifar100_mobilenetv2_x1_0',\n",
            " 'cifar100_mobilenetv2_x1_4',\n",
            " 'cifar100_repvgg_a0',\n",
            " 'cifar100_repvgg_a1',\n",
            " 'cifar100_repvgg_a2',\n",
            " 'cifar100_resnet20',\n",
            " 'cifar100_resnet32',\n",
            " 'cifar100_resnet44',\n",
            " 'cifar100_resnet56',\n",
            " 'cifar100_shufflenetv2_x0_5',\n",
            " 'cifar100_shufflenetv2_x1_0',\n",
            " 'cifar100_shufflenetv2_x1_5',\n",
            " 'cifar100_shufflenetv2_x2_0',\n",
            " 'cifar100_vgg11_bn',\n",
            " 'cifar100_vgg13_bn',\n",
            " 'cifar100_vgg16_bn',\n",
            " 'cifar100_vgg19_bn',\n",
            " 'cifar100_vit_b16',\n",
            " 'cifar100_vit_b32',\n",
            " 'cifar100_vit_h14',\n",
            " 'cifar100_vit_l16',\n",
            " 'cifar100_vit_l32',\n",
            " 'cifar10_mobilenetv2_x0_5',\n",
            " 'cifar10_mobilenetv2_x0_75',\n",
            " 'cifar10_mobilenetv2_x1_0',\n",
            " 'cifar10_mobilenetv2_x1_4',\n",
            " 'cifar10_repvgg_a0',\n",
            " 'cifar10_repvgg_a1',\n",
            " 'cifar10_repvgg_a2',\n",
            " 'cifar10_resnet20',\n",
            " 'cifar10_resnet32',\n",
            " 'cifar10_resnet44',\n",
            " 'cifar10_resnet56',\n",
            " 'cifar10_shufflenetv2_x0_5',\n",
            " 'cifar10_shufflenetv2_x1_0',\n",
            " 'cifar10_shufflenetv2_x1_5',\n",
            " 'cifar10_shufflenetv2_x2_0',\n",
            " 'cifar10_vgg11_bn',\n",
            " 'cifar10_vgg13_bn',\n",
            " 'cifar10_vgg16_bn',\n",
            " 'cifar10_vgg19_bn',\n",
            " 'cifar10_vit_b16',\n",
            " 'cifar10_vit_b32',\n",
            " 'cifar10_vit_h14',\n",
            " 'cifar10_vit_l16',\n",
            " 'cifar10_vit_l32']\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "from torchattacks import PGD\n",
        "import numpy as np\n",
        "from torchvision.transforms import v2\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import pickle\n",
        "import torch\n",
        "from pprint import pprint\n",
        "pprint(torch.hub.list(\"chenyaofo/pytorch-cifar-models\", force_reload=True))\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "75fdbfbd-4821-4d31-820c-aa5ecda819bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75fdbfbd-4821-4d31-820c-aa5ecda819bf",
        "outputId": "49c9fdd5-03a8-421a-d989-8b791aa6d064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GrZ3V7hC8M57",
      "metadata": {
        "id": "GrZ3V7hC8M57"
      },
      "source": [
        "##PEAS Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7fa192f4-cdad-4001-9dfa-3df5a05dbfe8",
      "metadata": {
        "id": "7fa192f4-cdad-4001-9dfa-3df5a05dbfe8"
      },
      "outputs": [],
      "source": [
        "class PEAS:\n",
        "    def __init__(self, F, g, S, trans, attack, count=200):\n",
        "        \"\"\"\n",
        "        Initializes the PEAS class.\n",
        "\n",
        "        Parameters:\n",
        "        - F (list): A list of models that will be used to evaluate the generated adversarial examples.\n",
        "        - g (model): The surrogate model used for generating adversarial examples.\n",
        "        - S (int): The scenario for augmentation: 0 (no augmentation), 1 (single augmentation), 2 (mix of augmentations).\n",
        "        - trans (list): The list of augmentations to apply.\n",
        "        - count (int, optional): The number of attack iterations to perform. Defaults to 200.\n",
        "        \"\"\"\n",
        "\n",
        "        self.F = F\n",
        "        self.g = g\n",
        "        self.S = S\n",
        "        self.trans = trans\n",
        "        self.count = count\n",
        "        self.attack = attack\n",
        "\n",
        "    def generate(self, x, y):\n",
        "\n",
        "        \"\"\"\n",
        "        Generates adversarial examples using the selected attack under various settings.\n",
        "\n",
        "        Parameters:\n",
        "        - x (Tensor): The input images.\n",
        "        - y (Tensor): The correct labels for the input images.\n",
        "\n",
        "        Returns:\n",
        "        - adv_x (Tensor): The generated adversarial examples.\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = len(x)\n",
        "        best_attacks = []\n",
        "        min_confidences = [float('inf')] * batch_size\n",
        "\n",
        "        for _ in tqdm(range(self.count)):\n",
        "\n",
        "\n",
        "            if self.S==0: #without augmentations\n",
        "                x_a = self.attack(x, y)\n",
        "\n",
        "            if self.S==1: #PEAS S1 - one augmentation\n",
        "                x_a = random.choice(self.trans)(x)\n",
        "                x_a = self.attack(x_a, y)\n",
        "\n",
        "            elif self.S==2: #PEAS S2 - mixing augmentations\n",
        "                augmentations = transforms.Compose(self.trans)\n",
        "                x_a = augmentations(x)\n",
        "                x_a = self.attack(x_a, y)\n",
        "\n",
        "            average_confidences =  np.zeros(batch_size, dtype=np.float32)\n",
        "\n",
        "\n",
        "            for model in self.F:\n",
        "                outputs = model(x_a).softmax(dim=1)\n",
        "                confidences = outputs[torch.arange(outputs.size(0)),y].detach().cpu().numpy()\n",
        "                average_confidences += confidences\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "            average_confidences /= len(F)\n",
        "\n",
        "            # Compare and select the attack with the lowest average confidence for each image\n",
        "            for i in range(batch_size):\n",
        "                if average_confidences[i] < min_confidences[i]:\n",
        "                    if len(best_attacks) < batch_size:\n",
        "                        best_attacks.append(x_a[i])\n",
        "                    else:\n",
        "                        best_attacks[i] = x_a[i]\n",
        "                    min_confidences[i] = average_confidences[i]\n",
        "\n",
        "        # Stack the selected attacks\n",
        "        adv_x = torch.stack(best_attacks)\n",
        "        return adv_x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RT4cZW518QV9",
      "metadata": {
        "id": "RT4cZW518QV9"
      },
      "source": [
        "##Parameters\n",
        "Define the names of the victim and substitute models, and the set of augmentation algorithms for subtle transformations. You can change these parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "775151da-2d7d-4dcf-9122-e9ca137b26b0",
      "metadata": {
        "id": "775151da-2d7d-4dcf-9122-e9ca137b26b0"
      },
      "outputs": [],
      "source": [
        "#Model names\n",
        "victim_name='resnet20'\n",
        "substitute_name='vgg11_bn'\n",
        "substitute_models_name = ['mobilenetv2_x0_5','shufflenetv2_x1_5','repvgg_a0']\n",
        "\n",
        "#Set of augmentation algorithms, each configured to perform a subtle augmentation. S1: random augmentation from the set , S2: applies all augmentations from the set.\n",
        "trans = [\n",
        "    transforms.RandomAffine(degrees=(-4,4), translate=(0.1, 0.1)), # Reduced degree of rotation and translation\n",
        "    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05), # Subtle color adjustments\n",
        "    transforms.RandomCrop(size=(32,32), padding=3), # Adjust padding if needed\n",
        "    transforms.GaussianBlur(kernel_size=1.9), # Smaller kernel for subtle blur\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=1.5), # Gentle sharpness adjustment\n",
        "    transforms.RandomAutocontrast()] # Generally subtle, adjust if necessary\n",
        "\n",
        "#Number of augmentations per input\n",
        "count = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "te0URMF4Cg-6",
      "metadata": {
        "id": "te0URMF4Cg-6"
      },
      "source": [
        "##Load and Normalize the Selected Models\n",
        " Load the sselected models from PyTorch Hub, apply normalization, and set the models to evaluation mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "QHvPt4l8D2Fn",
      "metadata": {
        "id": "QHvPt4l8D2Fn"
      },
      "outputs": [],
      "source": [
        "class model_with_normalization(nn.Module):\n",
        "    def __init__(self, model, normalization):\n",
        "        super(model_with_normalization, self).__init__()\n",
        "        self.model = model\n",
        "        self.normalization = normalization\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.normalization(x)\n",
        "        if x.shape == (3,224,224):\n",
        "          x = x.unsqueeze(0)\n",
        "        out = self.model(x)\n",
        "        return out\n",
        "\n",
        "normalization = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2471, 0.2435, 0.2616])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "UAcuEkYeB-D_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAcuEkYeB-D_",
        "outputId": "fb541317-21bd-4ad4-e067-94f477dae880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar10_resnet20-4118986f.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_resnet20-4118986f.pt\n",
            "100%|██████████| 1.09M/1.09M [00:00<00:00, 48.2MB/s]\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/vgg/cifar10_vgg11_bn-eaeebf42.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_vgg11_bn-eaeebf42.pt\n",
            "100%|██████████| 37.3M/37.3M [00:00<00:00, 49.3MB/s]\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/mobilenetv2/cifar10_mobilenetv2_x0_5-ca14ced9.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_mobilenetv2_x0_5-ca14ced9.pt\n",
            "100%|██████████| 2.85M/2.85M [00:02<00:00, 1.22MB/s]\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/shufflenetv2/cifar10_shufflenetv2_x1_5-296694dd.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_shufflenetv2_x1_5-296694dd.pt\n",
            "100%|██████████| 9.69M/9.69M [00:00<00:00, 55.9MB/s]\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/repvgg/cifar10_repvgg_a0-ef08a50e.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_repvgg_a0-ef08a50e.pt\n",
            "100%|██████████| 30.1M/30.1M [00:00<00:00, 43.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Victim Model\n",
        "victim = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_\"+str(victim_name), pretrained=True, verbose=False)\n",
        "victim = model_with_normalization(victim, normalization)\n",
        "victim = victim.to(device)\n",
        "victim.eval()\n",
        "\n",
        "\n",
        "#Substitute model to generate adversarial examples\n",
        "g = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_\"+str(substitute_name), pretrained=True,verbose=False)\n",
        "g = model_with_normalization(g, normalization)\n",
        "g.eval()\n",
        "g = g.to(device)\n",
        "\n",
        "\n",
        "#Set of substitute models to compute ET score\n",
        "F = []\n",
        "for model_name in substitute_models_name:\n",
        "    model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_\"+model_name, pretrained=True, verbose=False)\n",
        "    model = model.to(device)\n",
        "    model = model_with_normalization(model, normalization)\n",
        "    model.eval()\n",
        "    F.append(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MNPKBsitDPRK",
      "metadata": {
        "id": "MNPKBsitDPRK"
      },
      "source": [
        "##Select Correctly Classified Samples from CIFAR-10 Dataset\n",
        "Load the CIFAR-10 test dataset and create a DataLoader. Select 1000 random samples that are correctly classified by the victim model to avoid bias. The correctly classified samples are stored for further use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2dEZvuXuCpHE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dEZvuXuCpHE",
        "outputId": "17b25438-b17c-4498-adea-2c6fe34bc12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29913634.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n"
          ]
        }
      ],
      "source": [
        "#To avoid bias, we only used 1000 random samples that were correctly classified by the victim\n",
        "cifar_test = CIFAR10(root='./', train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), ]))\n",
        "# Create a DataLoader for the test dataset, typically shuffle is False\n",
        "cifar_test_loader = DataLoader(\n",
        "    cifar_test,\n",
        "    batch_size=100,  # Adjust the batch size as needed\n",
        "    shuffle=True,          # Set shuffle to False for the test dataset\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "\n",
        "correct_samples = []\n",
        "for batch, (images, labels) in enumerate(cifar_test_loader):\n",
        "    # Move images and labels to the same device as the model\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Get predictions\n",
        "    outputs = victim(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # Select correctly predicted samples\n",
        "    correct = predicted == labels\n",
        "    for img, label, is_correct in zip(images, labels, correct):\n",
        "        if is_correct and len(correct_samples) < 1000:\n",
        "            # Save image and label; convert tensors to CPU for serialization\n",
        "            correct_samples.append((img.cpu(), label.cpu()))\n",
        "\n",
        "    # Break the loop if we have enough samples\n",
        "    if len(correct_samples) >= 1000:\n",
        "        new_data_loader = DataLoader(correct_samples, batch_size=100, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basline Tranfer Attack\n",
        "Select the baseline attack to be boosted by PEAS."
      ],
      "metadata": {
        "id": "ua0M-EW2mAMa"
      },
      "id": "ua0M-EW2mAMa"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "eKpvrnDFsn72",
      "metadata": {
        "id": "eKpvrnDFsn72"
      },
      "outputs": [],
      "source": [
        "#The basline tranfer attack to boost by PEAS\n",
        "epsilon = 2/255\n",
        "PGD_attack = PGD(g, eps=epsilon , alpha=random.uniform(0.1/255, 0.3/255), steps=random.randint(10, 20), random_start=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-f8Ka-_Q-VQ3",
      "metadata": {
        "id": "-f8Ka-_Q-VQ3"
      },
      "source": [
        "##Calculate Attack Success Rate (ASR)\n",
        "Calculate the ASR for three scenarios: Vanilla (no augmentations), PEAS_S1 (single augmentation), and PEAS_S2 (mix of augmentations). Generate adversarial examples using the PEAS framework and evaluate them against the victim model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cfa0bb1b-7b79-4115-8f29-69e9efab6701",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfa0bb1b-7b79-4115-8f29-69e9efab6701",
        "outputId": "2970361e-1e40-4a29-d356-b74a6f5e926f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:01<00:00,  3.28it/s]\n",
            "100%|██████████| 200/200 [01:08<00:00,  2.91it/s]\n",
            "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
            "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
            "100%|██████████| 200/200 [01:06<00:00,  2.99it/s]\n",
            "100%|██████████| 200/200 [01:30<00:00,  2.22it/s]\n",
            "100%|██████████| 200/200 [01:01<00:00,  3.23it/s]\n",
            "100%|██████████| 200/200 [01:06<00:00,  3.00it/s]\n",
            "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
            "100%|██████████| 200/200 [01:01<00:00,  3.23it/s]\n",
            "100%|██████████| 200/200 [01:05<00:00,  3.04it/s]\n",
            "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
            "100%|██████████| 200/200 [01:02<00:00,  3.23it/s]\n",
            "100%|██████████| 200/200 [01:06<00:00,  3.01it/s]\n",
            "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
            "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
            "100%|██████████| 200/200 [01:06<00:00,  3.01it/s]\n",
            "100%|██████████| 200/200 [01:30<00:00,  2.22it/s]\n",
            "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
            "100%|██████████| 200/200 [01:05<00:00,  3.04it/s]\n",
            "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
            "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
            "100%|██████████| 200/200 [01:07<00:00,  2.97it/s]\n",
            "100%|██████████| 200/200 [01:30<00:00,  2.22it/s]\n",
            "100%|██████████| 200/200 [01:01<00:00,  3.25it/s]\n",
            "100%|██████████| 200/200 [01:06<00:00,  3.02it/s]\n",
            "100%|██████████| 200/200 [01:29<00:00,  2.23it/s]\n",
            "100%|██████████| 200/200 [01:02<00:00,  3.22it/s]\n",
            "100%|██████████| 200/200 [01:06<00:00,  2.99it/s]\n",
            "100%|██████████| 200/200 [01:29<00:00,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Vanilla': 200, 'PEAS_S1': 363, 'PEAS_S2': 528}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "ASR = {'Vanilla': 0 , 'PEAS_S1': 0, 'PEAS_S2': 0}\n",
        "\n",
        "for batch, (x, y) in enumerate(new_data_loader):\n",
        "\n",
        "    #vanilla-no augmetations\n",
        "    PEAS_attack = PEAS(F,g, 0, trans, PGD_attack, count=count)\n",
        "    x_a = PEAS_attack.generate(x, y)\n",
        "    x_a = x_a.to(device)\n",
        "    adv_label = victim(x_a).argmax(dim=1)\n",
        "    adv_label = adv_label.to('cpu')\n",
        "    ASR['Vanilla'] += int((y != adv_label).int().sum())\n",
        "\n",
        "    #S1: ONE augmentations\n",
        "    PEAS_attack = PEAS(F,g, 1, trans, PGD_attack, count=count)\n",
        "    x_a = PEAS_attack.generate(x, y)\n",
        "    x_a = x_a.to(device)\n",
        "    adv_label = victim(x_a).argmax(dim=1)\n",
        "    adv_label = adv_label.to('cpu')\n",
        "    ASR['PEAS_S1'] += int((y != adv_label).int().sum())\n",
        "\n",
        "\n",
        "    #S2: mixing augmentations\n",
        "    PEAS_attack = PEAS(F,g, 2, trans, PGD_attack, count=count)\n",
        "    x_a = PEAS_attack.generate(x, y)\n",
        "    x_a = x_a.to(device)\n",
        "    adv_label = victim(x_a).argmax(dim=1)\n",
        "    adv_label = adv_label.to('cpu')\n",
        "    ASR['PEAS_S2'] += int((y != adv_label).int().sum())\n",
        "\n",
        "\n",
        "print(ASR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "915d25c7-ff40-4089-bc6d-8a54cadc787f",
      "metadata": {
        "id": "915d25c7-ff40-4089-bc6d-8a54cadc787f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b6b878-4bc4-494f-e1ab-1792b151f8da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial Success Rates (ASR) on CIFAR10, victim: resnet20, Substitute: vgg11_bn\n",
            "Vanilla: 0.2\n",
            "PEAS_S1: 0.363\n",
            "PEAS_S2: 0.528\n"
          ]
        }
      ],
      "source": [
        "print(f\"Adversarial Success Rates (ASR) on CIFAR10, victim: {victim_name}, Substitute: {substitute_name}\")\n",
        "for method, rate in ASR.items():\n",
        "    print(f\"{method}: {rate/1000}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "F18YPiFZ6bR5"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "TEST_GPU",
      "language": "python",
      "name": "test_gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}